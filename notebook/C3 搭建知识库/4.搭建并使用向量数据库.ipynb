{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 搭建并使用向量数据库\n",
    "## 一、前序配置\n",
    "本节重点为搭建并使用向量数据库，因此读取数据后我们省去数据处理的环节直入主题，数据清洗等步骤可以参考第三节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../data_base/knowledge_db/easy_rl/强化学习入门指南.mp4', '../../data_base/knowledge_db/easy_rl/强化学习入门指南.srt', '../../data_base/knowledge_db/easy_rl/强化学习入门指南.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# 读取本地/项目的环境变量。\n",
    "# find_dotenv()寻找并定位.env文件的路径\n",
    "# load_dotenv()读取该.env文件，并将其中的环境变量加载到当前的运行环境中  \n",
    "# 如果你设置的是全局的环境变量，这行代码则没有任何作用。\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 如果你需要通过代理端口访问，你需要如下配置\n",
    "# os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'\n",
    "# os.environ[\"HTTP_PROXY\"] = 'http://127.0.0.1:7890'\n",
    "\n",
    "# 获取folder_path下所有文件路径，储存在file_paths里\n",
    "file_paths = []\n",
    "folder_path = '../../data_base/knowledge_db'\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_paths.append(file_path)\n",
    "print(file_paths[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.pdf import PyMuPDFLoader\n",
    "from langchain.document_loaders.markdown import UnstructuredMarkdownLoader\n",
    "\n",
    "# 遍历文件路径并把实例化的loader存放在loaders里\n",
    "loaders = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "\n",
    "    file_type = file_path.split('.')[-1]\n",
    "    if file_type == 'pdf':\n",
    "        loaders.append(PyMuPDFLoader(file_path))\n",
    "    elif file_type == 'md':\n",
    "        loaders.append(UnstructuredMarkdownLoader(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载文件并存储到text\n",
    "texts = []\n",
    "\n",
    "for loader in loaders: texts.extend(loader.load())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入后的变量类型为`langchain_core.documents.base.Document`, 文档变量类型同样包含两个属性\n",
    "- `page_content` 包含该文档的内容。\n",
    "- `meta_data` 为文档相关的描述性数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每一个元素的类型：<class 'langchain_core.documents.base.Document'>.\n",
      "------\n",
      "该文档的描述性数据：{'source': '../../data_base/knowledge_db/pumkin_book/pumpkin_book.pdf', 'file_path': '../../data_base/knowledge_db/pumkin_book/pumpkin_book.pdf', 'page': 1, 'total_pages': 196, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'xdvipdfmx (20200315)', 'creationDate': \"D:20230303170709-00'00'\", 'modDate': '', 'trapped': ''}\n",
      "------\n",
      "查看该文档的内容:\n",
      "前言\n",
      "“周志华老师的《机器学习》\n",
      "（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读\n",
      "者通过西瓜书对机器学习有所了解, 所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推\n",
      "导细节的读者来说可能“不太友好”\n",
      "，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充\n",
      "具体的推导细节。\n",
      "”\n",
      "读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，后来我们了解到，周\n",
      "老师之所以省去这些推导细节的真实原因是，他本尊认为“理工科数学基础扎实点的大二下学生应该对西瓜书\n",
      "中的推导细节无困难吧，要点在书里都有了，略去的细节应能脑补或做练习”\n",
      "。所以...... 本南瓜书只能算是我\n",
      "等数学渣渣在自学的时候记下来的笔记，希望能够帮助大家都成为一名合格的“理工科数学基础扎实点的大二\n",
      "下学生”\n",
      "。\n",
      "使用说明\n",
      "• 南瓜书的所有内容都是以西瓜书的内容为前置知识进行表述的，所以南瓜书的最佳使用方法是以西瓜书\n",
      "为主线，遇到自己推导不出来或者看不懂的公式时再来查阅南瓜书；\n",
      "• 对于初学机器学习的小白，西瓜书第1 章和第2 章的公式强烈不建议深究，简单过一下即可，等你学得\n",
      "有点飘的时候再回来啃都来得及；\n",
      "• 每个公式的解析和推导我们都力(zhi) 争(neng) 以本科数学基础的视角进行讲解，所以超纲的数学知识\n",
      "我们通常都会以附录和参考文献的形式给出，感兴趣的同学可以继续沿着我们给的资料进行深入学习；\n",
      "• 若南瓜书里没有你想要查阅的公式，\n",
      "或者你发现南瓜书哪个地方有错误，\n",
      "请毫不犹豫地去我们GitHub 的\n",
      "Issues（地址：https://github.com/datawhalechina/pumpkin-book/issues）进行反馈，在对应版块\n",
      "提交你希望补充的公式编号或者勘误信息，我们通常会在24 小时以内给您回复，超过24 小时未回复的\n",
      "话可以微信联系我们（微信号：at-Sm1les）\n",
      "；\n",
      "配套视频教程：https://www.bilibili.com/video/BV1Mh411e7VU\n",
      "在线阅读地址：https://datawhalechina.github.io/pumpkin-book（仅供第1 版）\n",
      "最新版PDF 获取地址：https://github.com/datawhalechina/pumpkin-book/releases\n",
      "编委会\n",
      "主编：Sm1les、archwalker、jbb0523\n",
      "编委：juxiao、Majingmin、MrBigFan、shanry、Ye980226\n",
      "封面设计：构思-Sm1les、创作-林王茂盛\n",
      "致谢\n",
      "特别感谢awyd234、\n",
      "feijuan、\n",
      "Ggmatch、\n",
      "Heitao5200、\n",
      "huaqing89、\n",
      "LongJH、\n",
      "LilRachel、\n",
      "LeoLRH、\n",
      "Nono17、\n",
      "spareribs、sunchaothu、StevenLzq 在最早期的时候对南瓜书所做的贡献。\n",
      "扫描下方二维码，然后回复关键词“南瓜书”\n",
      "，即可加入“南瓜书读者交流群”\n",
      "版权声明\n",
      "本作品采用知识共享署名-非商业性使用-相同方式共享4.0 国际许可协议进行许可。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = texts[1]\n",
    "print(f\"每一个元素的类型：{type(text)}.\", \n",
    "    f\"该文档的描述性数据：{text.metadata}\", \n",
    "    f\"查看该文档的内容:\\n{text.page_content[0:]}\", \n",
    "    sep=\"\\n------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第七章 文本扩展\n",
      "文本扩展是大语言模型的一个重要应用方向，它可以输入简短文本，生成更加丰富的长文。这为创作提供了强大支持，但也可能被滥用。因此开发者在使用时，必须谨记社会责任，避免生成有害内容。\n",
      "在本章中,我们将学习基于 OpenAI API 实现一个客户邮件自动生成的示例，用于根据客户反馈优化客服邮件。这里还会介绍“温度”（temperature）这一超参数，它可以控制文本生成的多样性。\n",
      "需要注意，扩展功能只应用来辅助人类创作，而非大规模自动生成内容。开发者应审慎使用，避免产生负面影响。只有以负责任和有益的方式应用语言模型，才能发挥其最大价值。相信践行社会责任的开发者可以利用语言模型的扩展功能，开发出真正造福人类的创新应用。\n",
      "一、定制客户邮件\n",
      "在这个客户邮件自动生成的示例中，我们将根据客户的评价和其中的情感倾向，使用大语言模型针对性地生成回复邮件。\n",
      "具体来说，我们先输入客户的评论文本和对应的情感分析结果(正面或者负面)。然后构造一个 Prompt，要求大语言模型基于这些信息来生成一封定制的回复电子邮件。\n",
      "下面先给出一个实例，包括一条客户评价和这个评价表达的情感。这为后续的语言模型生成回复邮件提供了关键输入信息。通过输入客户反馈的具体内容和情感态度，语言模型可以生成针对这个特定客户、考虑其具体情感因素的个性化回复。这种针对个体客户特点的邮件生成方式，将大大提升客户满意度。\n",
      "```python\n",
      "我们可以在推理那章学习到如何对一个评论判断其情感倾向\n",
      "sentiment = \"消极的\"\n",
      "一个产品的评价\n",
      "review = f\"\"\"\n",
      "他们在11月份的季节性销售期间以约49美元的价格出售17件套装，折扣约为一半。\\\n",
      "但由于某些原因（可能是价格欺诈），到了12月第二周，同样的套装价格全都涨到了70美元到89美元不等。\\\n",
      "11件套装的价格也上涨了大约10美元左右。\\\n",
      "虽然外观看起来还可以，但基座上锁定刀片的部分看起来不如几年前的早期版本那么好。\\\n",
      "不过我打算非常温柔地使用它，例如，\\\n",
      "我会先在搅拌机中将像豆子、冰、米饭等硬物研磨，然后再制成所需的份量，\\\n",
      "切换到打蛋器制作更细的面粉，或者在制作冰沙时先使用交叉切割刀片，然后使用平面刀片制作更细/不粘的效果。\\\n",
      "制作冰沙时，特别提示：\\\n",
      "将水果和蔬菜切碎并冷冻（如果使用菠菜，则轻轻煮软菠菜，然后冷冻直到使用；\\\n",
      "如果制作果酱，则使用小到中号的食品处理器），这样可以避免在制作冰沙时添加太多冰块。\\\n",
      "大约一年后，电机发出奇怪的噪音，我打电话给客服，但保修已经过期了，所以我不得不再买一个。\\\n",
      "总的来说，这些产品的总体质量已经下降，因此它们依靠品牌认可和消费者忠诚度来维持销售。\\\n",
      "货物在两天内到达。\n",
      "\"\"\"\n",
      "```\n",
      "在这个例子中，我们已经利用前面章节学到的方法，从客户评价中提取出其表达的情感倾向。这里是一条关于搅拌机的评论。现在我们要基于这条评论中的情感倾向，使用大语言模型自动生成一封回复邮件。\n",
      "以下述 Prompt 为例：首先明确大语言模型的身份是客户服务 AI 助手；它任务是为客户发送电子邮件回复；然后在三个反引号间给出具体的客户评论；最后要求语言模型根据这条反馈邮件生成一封回复，以感谢客户的评价。\n",
      "```python\n",
      "from tool import get_completion\n",
      "prompt = f\"\"\"\n",
      "你是一位客户服务的AI助手。\n",
      "你的任务是给一位重要客户发送邮件回复。\n",
      "根据客户通过“”分隔的评价，生成回复以感谢客户的评价。提醒模型使用评价中的具体细节\n",
      "用简明而专业的语气写信。\n",
      "作为“AI客户代理”签署电子邮件。\n",
      "客户评论：{review}评论情感：{sentiment}\n",
      "\"\"\"\n",
      "response = get_completion(prompt)\n",
      "print(response)\n",
      "通过这个Prompt,我们将具体的客户评论内容和需要表达的客服助手语气与要生成的回复邮件链接起来。语言模型可以在充分理解客户反馈的基础上，自动撰写恰当的回复。\n",
      "这种依据具体客户评价个性化回复的方法，将大大提升客户体验和满意度。\n",
      "二、引入温度系数\n",
      "大语言模型中的 “温度”(temperature) 参数可以控制生成文本的随机性和多样性。temperature 的值越大，语言模型输出的多样性越大；temperature 的值越小，输出越倾向高概率的文本。\n",
      "举个例子，在某一上下文中，语言模型可能认为“比萨”是接下来最可能的词，其次是“寿司”和“塔可”。若 temperature 为0，则每次都会生成“比萨”；而当 temperature 越接近 1 时，生成结果是“寿司”或“塔可”的可能性越大，使文本更加多样。\n",
      "图 1.7 温度系数\n",
      "一般来说，如果需要可预测、可靠的输出，则将 temperature 设置为0，在所有课程中，我们一直设置温度为零；如果需要更具创造性的多样文本，那么适当提高 temperature 则很有帮助。调整这个参数可以灵活地控制语言模型的输出特性。\n",
      "在下面例子中，针对同一段来信，我们提醒语言模型使用用户来信中的详细信息，并设置一个较高的 temperature ，运行两次，比较他们的结果有何差异。\n",
      "```python\n",
      "第一次运行\n",
      "prompt = f\"\"\"\n",
      "你是一名客户服务的AI助手。\n",
      "你的任务是给一位重要的客户发送邮件回复。\n",
      "根据通过“”分隔的客户电子邮件生成回复，以感谢客户的评价。\n",
      "如果情感是积极的或中性的，感谢他们的评价。\n",
      "如果情感是消极的，道歉并建议他们联系客户服务。\n",
      "请确保使用评论中的具体细节。\n",
      "以简明和专业的语气写信。\n",
      "以“AI客户代理”的名义签署电子邮件。\n",
      "客户评价：{review}评论情感：{sentiment}\n",
      "\"\"\"\n",
      "response = get_completion(prompt, temperature=0.7)\n",
      "print(response)\n",
      "第二次运行输出结果会发生变化：\n",
      "```python\n",
      "第二次运行\n",
      "prompt = f\"\"\"\n",
      "你是一名客户服务的AI助手。\n",
      "你的任务是给一位重要的客户发送邮件回复。\n",
      "根据通过“”分隔的客户电子邮件生成回复，以感谢客户的评价。\n",
      "如果情感是积极的或中性的，感谢他们的评价。\n",
      "如果情感是消极的，道歉并建议他们联系客户服务。\n",
      "请确保使用评论中的具体细节。\n",
      "以简明和专业的语气写信。\n",
      "以“AI客户代理”的名义签署电子邮件。\n",
      "客户评价：{review}评论情感：{sentiment}\n",
      "\"\"\"\n",
      "response = get_completion(prompt, temperature=0.7)\n",
      "print(response)\n",
      "温度（temperature）参数可以控制语言模型生成文本的随机性。温度为0时，每次使用同样的 Prompt，得到的结果总是一致的。而在上面的样例中，当温度设为0.7时，则每次执行都会生成不同的文本。\n",
      "所以，这次的结果与之前得到的邮件就不太一样了。再次执行同样的 Prompt,邮件内容还会有变化。因此。我建议读者朋友们可以自己尝试不同的 temperature ，来观察输出的变化。总体来说，temperature 越高，语言模型的文本生成就越具有随机性。可以想象，高温度下，语言模型就像心绪更加活跃，但也可能更有创造力。\n",
      "适当调节这个超参数,可以让语言模型的生成更富有多样性，也更能意外惊喜。希望这些经验可以帮助你在不同场景中找到最合适的温度设置。\n",
      "三、英文版\n",
      "1.1 定制客户邮件\n",
      "```python\n",
      "given the sentiment from the lesson on \"inferring\",\n",
      "and the original customer message, customize the email\n",
      "sentiment = \"negative\"\n",
      "review for a blender\n",
      "review = f\"\"\"\n",
      "So, they still had the 17 piece system on seasonal \\\n",
      "sale for around $49 in the month of November, about \\\n",
      "half off, but for some reason (call it price gouging) \\\n",
      "around the second week of December the prices all went \\\n",
      "up to about anywhere from between $70-$89 for the same \\\n",
      "system. And the 11 piece system went up around $10 or \\\n",
      "so in price also from the earlier sale price of $29. \\\n",
      "So it looks okay, but if you look at the base, the part \\\n",
      "where the blade locks into place doesn’t look as good \\\n",
      "as in previous editions from a few years ago, but I \\\n",
      "plan to be very gentle with it (example, I crush \\\n",
      "very hard items like beans, ice, rice, etc. in the \\ \n",
      "blender first then pulverize them in the serving size \\\n",
      "I want in the blender then switch to the whipping \\\n",
      "blade for a finer flour, and use the cross cutting blade \\\n",
      "first when making smoothies, then use the flat blade \\\n",
      "if I need them finer/less pulpy). Special tip when making \\\n",
      "smoothies, finely cut and freeze the fruits and \\\n",
      "vegetables (if using spinach-lightly stew soften the \\ \n",
      "spinach then freeze until ready for use-and if making \\\n",
      "sorbet, use a small to medium sized food processor) \\ \n",
      "that you plan to use that way you can avoid adding so \\\n",
      "much ice if at all-when making your smoothie. \\\n",
      "After about a year, the motor was making a funny noise. \\\n",
      "I called customer service but the warranty expired \\\n",
      "already, so I had to buy another one. FYI: The overall \\\n",
      "quality has gone done in these types of products, so \\\n",
      "they are kind of counting on brand recognition and \\\n",
      "consumer loyalty to maintain sales. Got it in about \\\n",
      "two days.\n",
      "\"\"\"\n",
      "```\n",
      "python\n",
      "prompt = f\"\"\"\n",
      "You are a customer service AI assistant.\n",
      "Your task is to send an email reply to a valued customer.\n",
      "Given the customer email delimited by, \\\n",
      "Generate a reply to thank the customer for their review.\n",
      "If the sentiment is positive or neutral, thank them for \\\n",
      "their review.\n",
      "If the sentiment is negative, apologize and suggest that \\\n",
      "they can reach out to customer service. \n",
      "Make sure to use specific details from the review.\n",
      "Write in a concise and professional tone.\n",
      "Sign the email as AI customer agent.\n",
      "Customer review: {review}\n",
      "Review sentiment: {sentiment}\n",
      "\"\"\"\n",
      "response = get_completion(prompt)\n",
      "print(response)\n",
      "```\n",
      "2.1 引入温度系数\n",
      "python\n",
      "prompt = f\"\"\"\n",
      "You are a customer service AI assistant.\n",
      "Your task is to send an email reply to a valued customer.\n",
      "Given the customer email delimited by, \\\n",
      "Generate a reply to thank the customer for their review.\n",
      "If the sentiment is positive or neutral, thank them for \\\n",
      "their review.\n",
      "If the sentiment is negative, apologize and suggest that \\\n",
      "they can reach out to customer service. \n",
      "Make sure to use specific details from the review.\n",
      "Write in a concise and professional tone.\n",
      "Sign the email as AI customer agent.\n",
      "Customer review: {review}\n",
      "Review sentiment: {sentiment}\n",
      "\"\"\"\n",
      "response = get_completion(prompt, temperature=0.7)\n",
      "print(response)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(texts[203].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加数据清洗\n",
    "\n",
    "import re\n",
    "pattern = re.compile(r'[^\\u4e00-\\u9fa5](\\n)[^\\u4e00-\\u9fa5]',re.DOTALL)\n",
    "\n",
    "for text in texts:\n",
    "    if text.metadata.get('source').split('.')[-1] == 'pdf':\n",
    "        text.page_content = re.sub(pattern,lambda match: match.group(0).replace('\\n', ''),text.page_content)\n",
    "        text.page_content = text.page_content.replace('•', '')\n",
    "        text.page_content = text.page_content.replace(' ', '')\n",
    "    elif text.metadata.get('source').split('.')[-1] == 'md':\n",
    "        text.page_content = text.page_content.replace('\\n\\n','\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 切分文档\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "split_docs = text_splitter.split_documents(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、构建Chroma向量库\n",
    "\n",
    "Langchain 集成了超过 30 个不同的向量存储库。我们选择 Chroma 是因为它轻量级且数据存储在内存中，这使得它非常容易启动和开始使用。\n",
    "\n",
    "LangChain 可以直接使用 OpenAI 和百度千帆的 Embedding，同时，我们也可以针对其不支持的 Embedding API 进行自定义，例如，我们可以基于 LangChain 提供的接口，封装一个 zhupuai_embedding，来将智谱的 Embedding API 接入到 LangChain 中。在本章的[附LangChain自定义Embedding封装讲解](./附LangChain自定义Embedding封装讲解.ipynb)中，我们以智谱 Embedding API 为例，介绍了如何将其他 Embedding API 封装到 LangChain\n",
    "中，欢迎感兴趣的读者阅读。\n",
    "\n",
    "**注：如果你使用智谱 API，你可以参考讲解内容实现封装代码，也可以直接使用我们已经封装好的代码[zhipuai_embedding.py](./zhipuai_embedding.py)，将该代码同样下载到本 Notebook 的同级目录，就可以直接导入我们封装的函数。在下面的代码 Cell 中，我们默认使用了智谱的 Embedding，将其他两种 Embedding 使用代码以注释的方法呈现，如果你使用的是百度 API 或者 OpenAI API，可以根据情况来使用下方 Cell 中的代码。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 OpenAI Embedding\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "# 使用百度千帆 Embedding\n",
    "# from langchain.embeddings.baidu_qianfan_endpoint import QianfanEmbeddingsEndpoint\n",
    "# 使用我们自己封装的智谱 Embedding，需要将封装代码下载到本地使用\n",
    "from zhipuai_embedding import ZhipuAIEmbeddings\n",
    "\n",
    "# 定义 Embeddings\n",
    "# embedding = OpenAIEmbeddings() \n",
    "embedding = ZhipuAIEmbeddings()\n",
    "# embedding = QianfanEmbeddingsEndpoint()\n",
    "\n",
    "# 定义持久化路径\n",
    "persist_directory = '../../data_base/vector_db/chroma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf '../../data_base/vector_db/chroma'  # 删除旧的数据库文件（如果文件夹中有文件的话），windows电脑请手动删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.chroma import Chroma\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=split_docs[:20], # 为了速度，只选择前 20 个切分的 doc 进行生成；使用千帆时因QPS限制，建议选择前 5 个doc\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory  # 允许我们将persist_directory目录保存到磁盘上\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在此之后，我们要确保通过运行 vectordb.persist 来持久化向量数据库，以便我们在未来的课程中使用。\n",
    "\n",
    "让我们保存它，以便以后使用！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量库中存储的数量：20\n"
     ]
    }
   ],
   "source": [
    "print(f\"向量库中存储的数量：{vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、向量检索\n",
    "### 3.1 相似度检索\n",
    "Chroma的相似度搜索使用的是余弦距离，即：\n",
    "$$\n",
    "similarity = cos(A, B) = \\frac{A \\cdot B}{\\parallel A \\parallel \\parallel B \\parallel} = \\frac{\\sum_1^n a_i b_i}{\\sqrt{\\sum_1^n a_i^2}\\sqrt{\\sum_1^n b_i^2}}\n",
    "$$\n",
    "其中$a_i$、$b_i$分别是向量$A$、$B$的分量。\n",
    "\n",
    "当你需要数据库返回严谨的按余弦相似度排序的结果时可以使用`similarity_search`函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"什么是大语言模型\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的内容数：3\n"
     ]
    }
   ],
   "source": [
    "sim_docs = vectordb.similarity_search(question,k=3)\n",
    "print(f\"检索到的内容数：{len(sim_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的第0个内容: \n",
      "算法参数（超参数）与模型参数.............................6\n",
      "2.2.2\n",
      "验证集...........................................6\n",
      "2.3\n",
      "性能度量\n",
      ".............................................6\n",
      "2.3.1\n",
      "式(2.2)到式(2.7)的解释.......................\n",
      "--------------\n",
      "检索到的第1个内容: \n",
      "→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》←_←5.5\n",
      "其他常见神经网络\n",
      "........................................455.5.1\n",
      "式(5.18)的解释\n",
      ".....................................455.5.2\n",
      "式(5.20)的解释\n",
      ".....................................4\n",
      "--------------\n",
      "检索到的第2个内容: \n",
      "式(4.8)的解释......................................394.4.3\n",
      "式(4.12)的解释\n",
      ".....................................394.5\n",
      "多变量决策树...........................................394.5.1\n",
      "图(4.10)的解释\n",
      ".......................\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for i, sim_doc in enumerate(sim_docs):\n",
    "    print(f\"检索到的第{i}个内容: \\n{sim_doc.page_content[:200]}\", end=\"\\n--------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 MMR检索\n",
    "如果只考虑检索出内容的相关性会导致内容过于单一，可能丢失重要信息。\n",
    "\n",
    "最大边际相关性 (`MMR, Maximum marginal relevance`) 可以帮助我们在保持相关性的同时，增加内容的丰富度。\n",
    "\n",
    "核心思想是在已经选择了一个相关性高的文档之后，再选择一个与已选文档相关性较低但是信息丰富的文档。这样可以在保持相关性的同时，增加内容的多样性，避免过于单一的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmr_docs = vectordb.max_marginal_relevance_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMR 检索到的第0个内容: \n",
      "算法参数（超参数）与模型参数.............................6\n",
      "2.2.2\n",
      "验证集...........................................6\n",
      "2.3\n",
      "性能度量\n",
      ".............................................6\n",
      "2.3.1\n",
      "式(2.2)到式(2.7)的解释.......................\n",
      "--------------\n",
      "MMR 检索到的第1个内容: \n",
      "前言\n",
      "“周志华老师的《机器学习》（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读\n",
      "者通过西瓜书对机器学习有所了解,所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推\n",
      "导细节的读者来说可能“不太友好”，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充\n",
      "具体的推导细节。”\n",
      "读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，后来我们\n",
      "--------------\n",
      "MMR 检索到的第2个内容: \n",
      "编委会\n",
      "主编：Sm1les、archwalker、jbb0523\n",
      "编委：juxiao、Majingmin、MrBigFan、shanry、Ye980226\n",
      "封面设计：构思-Sm1les、创作-林王茂盛\n",
      "致谢\n",
      "特别感谢awyd234、feijuan、Ggmatch、Heitao5200、huaqing89、LongJH、LilRachel、LeoLRH、Nono17、spareribs、suncha\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for i, sim_doc in enumerate(mmr_docs):\n",
    "    print(f\"MMR 检索到的第{i}个内容: \\n{sim_doc.page_content[:200]}\", end=\"\\n--------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_universe_2.x",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
